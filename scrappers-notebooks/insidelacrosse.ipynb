{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "opt.add_experimental_option(\"excludeSwitches\", [\"disable-popup-blocking\"])\n",
    "# opt.add_argument(\"--headless\")\n",
    "# chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install chromedriver\n",
    "# !pip install chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scrape_links = {\n",
    "    \"INSIDE LACROSSE (GIRLS)\": \"https://www.insidelacrosse.com/recruiting/allcommitments/girls\",               \n",
    "    \"INSIDE LACROSSE (BOYS)\": \"https://www.insidelacrosse.com/recruiting/allcommitments\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_name=\"../data/insidelacrosse\"\n",
    "if (not os.path.exists(output_folder_name)):\n",
    "    os.mkdir(output_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dynamic_main_table(\n",
    "    web_driver,\n",
    "    url,\n",
    "    range_input=1000,\n",
    "    sleep_interval=1\n",
    "    ):\n",
    "    web_driver = web_driver\n",
    "    url = url\n",
    "    web_driver.get(url)\n",
    "    sleep(5)\n",
    "    print(\"scrolling to laod complete main table\")\n",
    "    previous_length = 0\n",
    "    counter =0\n",
    "    for x in range (range_input):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(sleep_interval)\n",
    "        results=driver.find_elements(by=By.XPATH, value='.//table[@class=\"table box table-striped\"]')\n",
    "        if previous_length <= len(results):\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "        previous_length = len(results)\n",
    "        table_html = results[-1].get_attribute(\"outerHTML\")\n",
    "        # check if table is empty\n",
    "        df = pd.read_html(table_html)[0]\n",
    "        if df.shape[0] == 0:\n",
    "            break\n",
    "        if counter > 20:\n",
    "            print(\"table loading finished\")\n",
    "            break\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_main_table_from_loaded_page():\n",
    "    final_dfs=[]\n",
    "    print(\"retrieving all data.... \\n\")\n",
    "\n",
    "    #     get all table's data and concatenate them\n",
    "    results=driver.find_elements(by=By.XPATH, value='.//table[@class=\"table box table-striped\"]')\n",
    "    for each_table in results:\n",
    "        # Use Pandas to read HTML and convert it to a DataFrame\n",
    "        df = pd.read_html(each_table.get_attribute(\"outerHTML\"))[0]\n",
    "        links = []\n",
    "        for row_index, row in df.iterrows():\n",
    "            link_elements = each_table.find_elements(by=By.XPATH, value=f'.//tr[{row_index + 1}]/td[1]//a')\n",
    "            # Extract the href attribute from the first link element, if any\n",
    "            link = link_elements[0].get_attribute(\"href\") if link_elements else None\n",
    "            links.append(link)\n",
    "        # Add a new column to the DataFrame with the extracted links\n",
    "        df[\"Link\"] = links\n",
    "        final_dfs.append(df)\n",
    "    result_df=pd.concat(final_dfs, axis=0, ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_dynamic_main_table(driver,scrape_links['INSIDE LACROSSE (GIRLS)'],sleep_interval=3):\n",
    "    scrapped_df=fetch_main_table_from_loaded_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scrape_links.keys():\n",
    "    print(f\"scrapping for {key}\\n\")\n",
    "    print(scrape_links[key])\n",
    "    driver.get(scrape_links[key])\n",
    "    sleep(5)\n",
    "    \n",
    "    print(\"scrolling to load all the tables....\\n\")\n",
    "    for x in range (0,1000):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(5)  # Adding a delay to wait for the new content to load\n",
    "        # results=driver.find_elements_by_xpath('.//table[@class=\"table box table-striped\"]')\n",
    "        results=driver.find_element(By.XPATH, './/table[@class=\"table box table-striped\"]')\n",
    "\n",
    "        # table_html = results[-1].get_attribute(\"outerHTML\")\n",
    "        table_html = results.get_attribute(\"outerHTML\")\n",
    "        \n",
    "        # Use Pandas to read HTML and convert it to a DataFrame\n",
    "        df = pd.read_html(table_html)[0]\n",
    "        if df.shape[0] == 0:\n",
    "            break\n",
    "    final_dfs=[]\n",
    "    print(\"retrieving all data.... \\n\")\n",
    "    \n",
    "    results=driver.find_elements(By.XPATH,'.//table[@class=\"table box table-striped\"]')\n",
    "    for each_table in results:\n",
    "\n",
    "        # Use Pandas to read HTML and convert it to a DataFrame\n",
    "        df = pd.read_html(each_table.get_attribute(\"outerHTML\"))[0]\n",
    "        final_dfs.append(df)\n",
    "    result_df=pd.concat(final_dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f\"{result_df.shape} records found\")\n",
    "    \n",
    "    result_df.to_csv(f\"{output_folder_name}/{key.replace(' ','_').lower()}.csv\", index =False)\n",
    "    \n",
    "    print(\"csv SAVED\")\n",
    "    \n",
    "print(\"Completed \")\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### workshop area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.insidelacrosse.com/recruiting/allcommitments/girls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=driver.find_elements(By.XPATH, './/table[@class=\"table box table-striped\"]')\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = results[-1].get_attribute(\"outerHTML\")\n",
    "df = pd.read_html(table_html)[0]\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load complete table page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.insidelacrosse.com/recruiting/allcommitments/girls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(link)\n",
    "print('sleeping ... ')\n",
    "length=-1\n",
    "sleep(5)\n",
    "print('scrolling started')\n",
    "for x in range (0,100):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(5)  # Adding a delay to wait for the new content to load\n",
    "    # results=driver.find_elements_by_xpath('.//table[@class=\"table box table-striped\"]')\n",
    "    results=driver.find_elements(By.XPATH, './/table[@class=\"table box table-striped\"]')\n",
    "    print('table found : '+str(len(results)))\n",
    "    if len(results) > length:\n",
    "        length=len(results)\n",
    "    else:\n",
    "        print(len(results))\n",
    "        break\n",
    "    # table_html = results[-1].get_attribute(\"outerHTML\")\n",
    "    # table_html = results.get_attribute(\"outerHTML\")\n",
    "    \n",
    "    # # Use Pandas to read HTML and convert it to a DataFrame\n",
    "    # df = pd.read_html(table_html)[0]\n",
    "    # if df.shape[0] == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=driver.find_elements(By.XPATH, './/table[@class=\"table box table-striped\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'.//table[@class=\"alert alert-danger\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'.//[@class=\"col-xs-12 text-xs-center m-b-2\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, './/table[@class=\"table box table-striped\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=driver.find_elements(By.ID,'.//table[@id=\"load_notice\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs=[]\n",
    "print(\"retrieving all data.... \\n\")\n",
    "results=driver.find_elements(By.XPATH,'.//table[@class=\"table box table-striped\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_table in results:\n",
    "\n",
    "    # Use Pandas to read HTML and convert it to a DataFrame\n",
    "    df = pd.read_html(each_table.get_attribute(\"outerHTML\"))[0]\n",
    "    final_dfs.append(df)\n",
    "result_df=pd.concat(final_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"{result_df.shape} records found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dee183c1ab44ac1d4c1e637787782bfafcb5ea2442cd0a4291b50d441210934d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
