{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "opt.add_experimental_option(\"excludeSwitches\", [\"disable-popup-blocking\"])\n",
    "opt.add_argument(\"--headless\")\n",
    "# opt.add_argument(\"--lang=en\")\n",
    "# import chromedriver_autoinstaller\n",
    "# chromedriver_autoinstaller.install()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_FLAG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_folder=\"../data/raw/campsandclinincs/\"\n",
    "output_folder_name=\"mass_elite\"\n",
    "output_file_name=\"mass_elite\"\n",
    "output_file_path = os.path.join(root_data_folder,output_folder_name)\n",
    "if (not os.path.exists(output_file_path)):\n",
    "    os.makedirs(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link=\"https://www.masselite.com/team/college-camps-and-clinics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=opt)\n",
    "print(f\"getting {base_link}\")\n",
    "driver.get(base_link)\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_webpage(\n",
    "        weblink:str,\n",
    "        driver_obj:object,\n",
    "        sleep_time=2,\n",
    "        increment=1,\n",
    "        limit=10\n",
    "    ):\n",
    "    \"\"\"to load webpage recursively\"\"\"\n",
    "    print(f\"getting {weblink}\")\n",
    "    driver_obj.get(weblink)\n",
    "    print('loading webspage ... '+str(sleep_time+increment))\n",
    "    if limit < sleep_time+increment:\n",
    "        return False\n",
    "    sleep(sleep_time)\n",
    "    # check if page is loaded\n",
    "    if not EC.presence_of_element_located('.//table[@class=\"tablepress tablepress-id-47 dataTable no-footer\"]'):\n",
    "        return load_webpage(weblink=weblink,driver_obj=driver_obj,sleep_time=sleep_time+increment,increment=increment,limit=limit)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping all rows please wait....\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"scrapping all rows please wait....\")\n",
    "    table = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, './/table[@class=\"tablepress tablepress-id-47 dataTable no-footer\"]'))\n",
    "            )\n",
    "    df_main = pd.read_html(table.get_attribute(\"outerHTML\"))[0]\n",
    "    all_links=[]\n",
    "    rows = table.find_elements(by=By.XPATH, value=\".//tr\")\n",
    "\n",
    "    # Iterate through each row\n",
    "    for row in rows:\n",
    "        # Extract the cells of the current row\n",
    "        cells = row.find_elements(by=By.XPATH, value=\".//td\")\n",
    "\n",
    "        # Check if the row has cells\n",
    "        if cells:\n",
    "            # Get the last cell of the row\n",
    "            last_cell = cells[-1]\n",
    "\n",
    "            # Check if the last cell contains a link\n",
    "            link = last_cell.find_element(by=By.XPATH, value=\".//a[@href]\").get_attribute(\"href\")\n",
    "\n",
    "            all_links.append(link)\n",
    "    df_main['CAMP LINK']=all_links\n",
    "    # convert list of dicts to data frame\n",
    "except Exception as e:\n",
    "    print(\"couldnt scrape the data\\n exception occured\" )\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed,\n",
      "(62, 5) record found, \n",
      "File saved successfully...\n"
     ]
    }
   ],
   "source": [
    "if WRITE_FLAG:\n",
    "    if df_main.shape != '(0,0)':\n",
    "        df_main.to_csv(f\"{output_file_path}/{output_file_name}.csv\", index=False)\n",
    "        print(f'completed,\\n{df_main.shape} record found, \\nFile saved successfully...')\n",
    "    else:\n",
    "        print('data frame is empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
