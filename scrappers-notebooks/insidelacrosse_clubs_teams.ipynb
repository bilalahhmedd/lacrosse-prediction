{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bilal/.local/lib/python3.8/site-packages/chromedriver_autoinstaller/123/chromedriver'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "opt.add_experimental_option(\"excludeSwitches\", [\"disable-popup-blocking\"])\n",
    "\n",
    "# opt.add_argument(\"--lang=en\")\n",
    "\n",
    "# chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file=\"sample.xlsx\"\n",
    "team_gender=\"boys\"\n",
    "output_folder_name=f\"clubs_teams_{team_gender}\"\n",
    "output_folder = os.path.join('../data/insidelacrosse/',output_folder_name)\n",
    "if (not os.path.exists(output_folder)):\n",
    "    os.mkdir(output_folder)\n",
    "    print('folder created: '+str(output_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laxachusetts</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://www.insidelacrosse.com/recruiting/club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laxachusetts</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.insidelacrosse.com/recruiting/club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICON</td>\n",
       "      <td>2017</td>\n",
       "      <td>https://www.insidelacrosse.com/recruiting/club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICON</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://www.insidelacrosse.com/recruiting/club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICON</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.insidelacrosse.com/recruiting/club...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Club Name  Year                                               Link\n",
       "0  Laxachusetts  2017  https://www.insidelacrosse.com/recruiting/club...\n",
       "1  Laxachusetts  2018  https://www.insidelacrosse.com/recruiting/club...\n",
       "2          ICON  2017  https://www.insidelacrosse.com/recruiting/club...\n",
       "3          ICON  2018  https://www.insidelacrosse.com/recruiting/club...\n",
       "4          ICON  2019  https://www.insidelacrosse.com/recruiting/club..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df=pd.read_excel(input_file)\n",
    "\n",
    "driver = webdriver.Chrome(options=opt)\n",
    "\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_each_team_players(team_class_list):\n",
    "    driver = webdriver.Chrome(options=opt)\n",
    "    driver.get(team_class_list[-1])\n",
    "    df_player=pd.DataFrame()\n",
    "    try:\n",
    "        wait_for__player_table = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, './/table[@class=\"table box table-striped\"]'))\n",
    "        )\n",
    "        sleep(1)\n",
    "        \n",
    "        player_table=driver.find_element(by=By.XPATH, value='.//table[@class=\"table box table-striped\"]')\n",
    "        player_table\n",
    "        table_html = player_table.get_attribute('outerHTML')\n",
    "\n",
    "        # Convert HTML table to DataFrame\n",
    "        df_player = pd.read_html(table_html)[0]\n",
    "        rows = player_table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "\n",
    "        # Initialize an empty list to store the counts of full stars\n",
    "        full_star_counts = []\n",
    "\n",
    "        # Loop through each row\n",
    "        for row in rows:\n",
    "            # Find the last column in each row (rating column)\n",
    "            rating_column = row.find_element(By.XPATH, \".//td[last()]\")\n",
    "\n",
    "\n",
    "            # Count the number of full stars (icon-star-full elements)\n",
    "            full_star_count = rating_column.find_elements(By.XPATH, \".//i[@class='icon-star-full']\")\n",
    "\n",
    "            # Append the count to the list\n",
    "            full_star_counts.append(len(full_star_count))\n",
    "        df_player['Rating'] = full_star_counts\n",
    "        \n",
    "        \n",
    "        df_player[\"team_name\"]=team_class_list[0]\n",
    "        df_player[\"year\"]=team_class_list[1]\n",
    "        \n",
    "        \n",
    "    except:\n",
    "#         no table found\n",
    "        pass\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return df_player\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping for Laxachusetts     2017   at 1 index\n",
      "scrapping for each team in parallel for   2 teams\n",
      "scrapping for Laxachusetts     2018   at 2 index\n",
      "scrapping for each team in parallel for   3 teams\n",
      "scrapping for ICON     2017   at 3 index\n",
      "scrapping for each team in parallel for   1 teams\n",
      "scrapping for ICON     2018   at 4 index\n",
      "no teams found\n",
      "scrapping for ICON     2019   at 5 index\n",
      "scrapping for each team in parallel for   2 teams\n"
     ]
    }
   ],
   "source": [
    "for index , row in main_df.iterrows():\n",
    "    base_link=row[\"Link\"]\n",
    "    \n",
    "    \n",
    "    driver.get(base_link)\n",
    "    print(f\"scrapping for {row['Club Name']}     { str(row['Year'])}   at {str(index+1)} index\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        wait_for_tables = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, './/table[@class=\"table table-striped box\"]'))\n",
    "        )\n",
    "        sleep(1)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# all tables (boys and girls)\n",
    "        results=driver.find_elements(by=By.XPATH, value='.//table[@class=\"table table-striped box\"]')\n",
    "        \n",
    "        for each_table in results:\n",
    "            header = each_table.find_element(By.XPATH, './/tr[1]/th[1]').text\n",
    "        #         find specific gender table \n",
    "            if team_gender.lower()  in header.lower():\n",
    "#                 get all team names, its links and class\n",
    "\n",
    "                team_names_cells=each_table.find_elements(By.XPATH, './/tr/td[1]')\n",
    "                team_names = [team.text for team in team_names_cells]\n",
    "\n",
    "\n",
    "\n",
    "                team_class_cells=each_table.find_elements(By.XPATH, './/tr/td[2]')\n",
    "                team_classes = [class_.text for class_ in team_class_cells]\n",
    "\n",
    "\n",
    "\n",
    "                hrefs = each_table.find_elements(By.XPATH, './/tr/td[1]//a[@href]')\n",
    "\n",
    "                # Extract href attributes and store them in a list of teams \n",
    "                href_values = [href.get_attribute('href') for href in hrefs]\n",
    "\n",
    "\n",
    "                merged_list = list(zip(team_names, team_classes, href_values))\n",
    "                list_of_lists_teams_n_class = [list(t) for t in merged_list]\n",
    "                \n",
    "#                 scrape for each team in parallel\n",
    "\n",
    "                print(f\"scrapping for each team in parallel for   {str(len(list_of_lists_teams_n_class))} teams\")\n",
    "\n",
    "\n",
    "                with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers as needed\n",
    "                    # Use executor.map to apply the function to each URL in parallel\n",
    "                    result_dfs = executor.map(scrape_each_team_players, list_of_lists_teams_n_class)\n",
    "                concatenated_df = pd.concat(result_dfs, ignore_index=True)\n",
    "                \n",
    "                \n",
    "                concatenated_df.to_csv(f'{output_folder_name}/{row[\"Club Name\"].replace(\" \",\"_\")}_{str(row[\"Year\"])}.csv')\n",
    "                \n",
    "                \n",
    "    except:\n",
    "        print(\"no teams found\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed....\n"
     ]
    }
   ],
   "source": [
    "print(\"completed....\")\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
