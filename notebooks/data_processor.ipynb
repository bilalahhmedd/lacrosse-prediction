{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' data processing script '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" data processing script \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_alpha_numeric_ended(file_name:str):\n",
    "    \"\"\" end name with alphanumeric character only \"\"\"\n",
    "    if file_name[-1].isalnum():\n",
    "        return file_name\n",
    "    else:\n",
    "        file_name=file_name[:-1]\n",
    "    return name_alpha_numeric_ended(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revamp_file_name(file_name:str):\n",
    "    \"\"\" rename csv file according to convention \"\"\"\n",
    "    # lower name, \n",
    "    # replace space and dash with underscore,\n",
    "    # remove comma, colon, semicolon etc from name,\n",
    "    # last character should be alphabat,\n",
    "    file_name= file_name.lower().translate(str.maketrans({' ':'_','-':'_','\"':'',\"'\":\"\"}))\n",
    "    name, ext = os.path.splitext(file_name)\n",
    "    name= name_alpha_numeric_ended(name)\n",
    "    file_name=name+ext\n",
    "    file_name= file_name.replace('mens','men')\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Populate Gender Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append gender there\n",
    "boys_identifiers = ['boy','boys','man','men']\n",
    "girl_identifiers = ['girl','girls','woman','women','commitment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender(file_name_string):\n",
    "    \"\"\" method to identify gender for given file name \"\"\"\n",
    "    for y in boys_identifiers:\n",
    "        if y in file_name_string and \"wo\"+y not in file_name_string:\n",
    "            return 'boy' \n",
    "    for x in girl_identifiers:\n",
    "        if x in file_name_string:\n",
    "            return 'girl' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_df_with_gender(input_df:object,input_string:str):\n",
    "    \"\"\" populate dataframe with new column gender \"\"\"\n",
    "    output_df = input_df\n",
    "    output_df['gender']=identify_gender(input_string)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processors Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns names finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'high_school',\n",
       " 'state',\n",
       " 'commitment_year',\n",
       " 'club',\n",
       " 'club_year',\n",
       " 'gender',\n",
       " 'college',\n",
       " 'position',\n",
       " 'height',\n",
       " 'width',\n",
       " 'club_rank']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names_required = [\n",
    "    'name',\n",
    "    'high_school',\n",
    "    'state',\n",
    "    'commitment_year',\n",
    "    'club',\n",
    "    'club_year',\n",
    "    'gender',\n",
    "    'college',\n",
    "    'position',\n",
    "    'height',\n",
    "    'width',\n",
    "    'club_rank',\n",
    "    ]\n",
    "column_names_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_dataframes_from_folder(folder_path:str):\n",
    "    \"\"\" method to read multiple csv files inside single folder\"\"\"\n",
    "    output_dfs_dict = {}\n",
    "    for file in os.listdir(folder_path):\n",
    "        output_dfs_dict[file]=pd.read_csv(os.path.join(folder_path,file))\n",
    "    return output_dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_col_names(\n",
    "    input_df:object,\n",
    "    col_names_map_dict:dict\n",
    "    ):\n",
    "    \"\"\" map scrapped csv col names to required column names list \"\"\"\n",
    "    return input_df.rename(columns=col_names_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_first_last(\n",
    "    input_df:object,\n",
    "    cols_to_merge = ['First','Last'],\n",
    "    new_col_name = 'name'\n",
    "    ):\n",
    "    \"\"\" merge First Name, Last Name column into one column called name \"\"\"\n",
    "    output_df = input_df\n",
    "    for col in cols_to_merge:\n",
    "        output_df[col]=output_df[col].astype(str)\n",
    "    output_df[new_col_name]= output_df[cols_to_merge].agg(' '.join, axis=1)\n",
    "    output_df = output_df.drop(cols_to_merge,axis=1)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_names_lower(input_df:object):\n",
    "    \"\"\" lower column names \"\"\"\n",
    "    return input_df.set_axis([x.lower() for x in list(input_df.columns)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_names_underscore_separated(input_df:object):\n",
    "    \"\"\"make column names single underscore separated\"\"\"\n",
    "    return input_df.set_axis([re.sub(' +','_',x) for x in list(input_df.columns)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnamed_columns(input_df):\n",
    "    \"\"\" drop unnamed columns from dataframe \"\"\"\n",
    "    df_ = input_df\n",
    "    df_ = df_.loc[:, ~df_.columns.str.contains('^unnamed')]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_col_names(\n",
    "    input_df:object,\n",
    "    col_names_map_dict:dict,\n",
    "    source_website='laxnumbers'\n",
    "    ):\n",
    "    \"\"\" refactor column names to keep consistency and follow naming convention (lowercase, underscore-separated \"\"\"\n",
    "    output_df = input_df\n",
    "    if source_website == 'americanselectlacrosse':\n",
    "        output_df = merge_first_last(\n",
    "            output_df,\n",
    "            ['First','Last'],\n",
    "            'name'\n",
    "        )\n",
    "    elif source_website == 'toplaxrecruits':\n",
    "        output_df = merge_first_last(\n",
    "            output_df,\n",
    "            ['First Name','Last Name'],\n",
    "            'name'\n",
    "        )\n",
    "    output_df=map_col_names(output_df,col_names_map_dict)\n",
    "    output_df=set_col_names_lower(output_df)\n",
    "    output_df=set_col_names_underscore_separated(output_df)\n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### populate commitment year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate commitment year in dataframe\n",
    "\n",
    "def get_year_from_string(file_name:str):\n",
    "    \"\"\" detects year from file name string \"\"\"\n",
    "    try:\n",
    "        output = re.match(r'.*([1-3][0-9]{3})', file_name).group(1)\n",
    "        return output\n",
    "    except:\n",
    "        print('year not found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_commitment_year_from_filename(input_df,file_name:None):\n",
    "    \"\"\" populate dataframe using  year from filename string \"\"\"\n",
    "    year = get_year_from_string(file_name)\n",
    "    output_df = input_df\n",
    "    output_df['commitment_year']=year\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### columns mapping dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_select_names_map_dict = {\n",
    "    'Region':'state',\n",
    "    'School': 'college',\n",
    "    'CLUB TEAM':'club',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clublacrose_names_map_dict = {\n",
    "    'Player Name':'name',\n",
    "    'University':'college',\n",
    "    'Division': 'commitment_year',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "laxnumbers_names_map_dict = {\n",
    "    'Name':'name',\n",
    "    'State': 'state',\n",
    "    'Club': 'club',\n",
    "    'Previous  School':'high_school',\n",
    "    'Class':'commitment_year',\n",
    "    'Pos':'position'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toplax_names_map_dict = {\n",
    "    'High School Name':'high_school',\n",
    "    'Grad Year':'commitment_year',\n",
    "    'Graduation Year':'commitment_year',\n",
    "    'region':'state',\n",
    "    'ST':'state',\n",
    "    'COLLEGE COMMITTED TO': 'college',\n",
    "    'College Committed To/Signed With':'college',\n",
    "    'College Committed to':'college',\n",
    "    'Club Team':'club',\n",
    "    'DIV':'division'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __main__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAW TO BRONZE Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process data from raw to bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = '../data/'\n",
    "FOLDER_NAME = 'americanselectlacrosse'\n",
    "WRITE_FLAG = True\n",
    "COLS_TO_MERGE = ['First','Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_process_data_from_raw_folder(\n",
    "        raw_folder_path:str,\n",
    "        column_names_map_dict:object\n",
    "    ):\n",
    "    \"\"\" read csv files and extract and transform data ready for bronze layer \"\"\"\n",
    "    csv_dfs_dict = get_csv_dataframes_from_folder(raw_folder_path)\n",
    "    print('csv dfs read success')\n",
    "    source_website_name = raw_folder_path.split('/')[-2]\n",
    "    print(source_website_name)\n",
    "    bronze_csv_dfs_dict = {}\n",
    "    for raw_file_name, df in csv_dfs_dict.items():\n",
    "        if \"americanselect\" in raw_file_name:\n",
    "            # populate commitment year from file name\n",
    "            df=populate_commitment_year_from_filename(df,raw_file_name)\n",
    "            # merge first and last column names\n",
    "            df = merge_first_last(df,['First','Last'],'name')\n",
    "        if \"toplax\" in raw_file_name:\n",
    "            df = merge_first_last(df,['First Name','Last Name'],'name')\n",
    "        \n",
    "        bronze_file_name = revamp_file_name(raw_file_name)\n",
    "        # refactor column names\n",
    "        df_refactored = refactor_col_names(df,column_names_map_dict,source_website_name)\n",
    "        # populate dataframe with gender column\n",
    "        df_refactored = populate_df_with_gender(df_refactored,raw_file_name)\n",
    "\n",
    "        # populate missing columns from required list with None value default\n",
    "        missing_columns = list(set(column_names_required)-set(list(df_refactored.columns)))\n",
    "        df_refactored[missing_columns]=None\n",
    "        df_refactored = drop_unnamed_columns(df_refactored)\n",
    "        bronze_csv_dfs_dict[bronze_file_name]=df_refactored\n",
    "        \n",
    "    return bronze_csv_dfs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dfs_dict_to_folder(\n",
    "    input_dict:dict,\n",
    "    folder_path:str\n",
    "    ):\n",
    "    \"\"\" writes dataframes in dict into target folder \"\"\"\n",
    "    for file_name, df in input_dict.items():\n",
    "        df.to_csv(os.path.join(folder_path,file_name))\n",
    "        print(file_name+' written to '+folder_path+ ' success ... ')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bronze_to_silver(\n",
    "        bronze_folder_path:str,\n",
    "        unique_columns = [],\n",
    "    ):\n",
    "    # read all csv files\n",
    "    # concat all dataframe into one \n",
    "    # deal null values\n",
    "    # dedupe based on unique columns\n",
    "    dfs = []\n",
    "    for root,dirs,files in os.walk(bronze_folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                dfs.append(pd.read_csv(os.path.join(root,file)))\n",
    "    final_df = pd.concat(dfs)\n",
    "    # now dedupe based on unique columns\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(2,'../etl/')\n",
    "from data_helper import process_data_from_bronze_to_silver\n",
    "from data_helper import process_data_from_sliver_to_gold\n",
    "from data_helper import create_none_existing_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/commitments/silver already exists\n",
      "../data/commitments/gold already exists\n"
     ]
    }
   ],
   "source": [
    "# process brozne to silver\n",
    "\n",
    "bronze_folder_path = '../data/commitments/bronze'\n",
    "silver_folder_path = '../data/commitments/silver'\n",
    "gold_folder_path = '../data/commitments/gold'\n",
    "create_none_existing_folder(silver_folder_path)\n",
    "create_none_existing_folder(gold_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting from clublacrosse\n",
      "saving into silver folder ../data/commitments/silver\n",
      "success \n",
      "extracting from americanselectlacrosse\n",
      "saving into silver folder ../data/commitments/silver\n",
      "success \n",
      "extracting from laxnumbers\n",
      "saving into silver folder ../data/commitments/silver\n",
      "success \n",
      "extracting from toplaxrecruits\n",
      "saving into silver folder ../data/commitments/silver\n",
      "success \n"
     ]
    }
   ],
   "source": [
    "process_data_from_bronze_to_silver(bronze_folder_path,silver_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data from ../data/commitments/silver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bilal/Desktop/lancing/lacrosse-prediction/notebooks/../etl/data_helper.py:255: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  dfs_dict = get_csv_dataframes_from_folder(silver_folder_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving into ../data/commitments/gold\n",
      "commitments.csv saved success\n"
     ]
    }
   ],
   "source": [
    "process_data_from_sliver_to_gold(\n",
    "    silver_folder_path=silver_folder_path,\n",
    "    gold_folder_path=gold_folder_path,\n",
    "    output_file_name='commitments.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
